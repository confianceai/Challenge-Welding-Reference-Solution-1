{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fc2a1a-843c-460f-84d3-8e05e04375eb",
   "metadata": {},
   "source": [
    "# Test your AI component compatibility\n",
    "\n",
    "This notebook demonstrates how your AI component can be built and tested to determine if it will be compatible with the pipeline evaluation process.\n",
    "\n",
    "This notebook provides an overview of how an AI component candidate will be evaluated. Even though it does not compute metrics, it gives a precise idea of how to build a compatible AI component and how it is used in inference for score generation.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The task is to build an AI component whose main objective is to predict the welding state from a given image.\n",
    "\n",
    "### Inputs to the AI component\n",
    "The AI component shall take the following inputs: \n",
    "- A list of numpy arrays representing the input images to process . \n",
    "- A list of dictionnaries containing a meta-description of the images.\n",
    "\n",
    "### Outputs of the AI component  \n",
    "It shall return a dictionnary with four keys {predictions , probabilities, OOD_score, explainabilities}\n",
    "    \n",
    "The first key is required:   \n",
    "- *predictions*:  The list of predicted welding state. The welding state can have three possible values: [OK, KO, UNKNOWN]\n",
    "    \n",
    "The following keys are not mandatory, but their presence will significantly contribute to the improvement of the quality score for the developed AI component:\n",
    "\n",
    "- *probabilities*:  The list of associated probabilities for each image. The list should have the format: [$P_{KO}$, $P_{OK}$, $P_{UNKNWON}$]  where $\\sum_{i \\in \\{\\text{OK, KO, UNKNOWN}\\}} P_i = 1$.\n",
    "\n",
    "- *OOD_scores*: The list of OOD scores predicted by the AI component for each images. This score (X) is a real positive number. If $0\\leq X < 1$ the image is considered as *In-Domain*, if $X >1$ the image is considered as *Out-of-Domain (OoD)*.\n",
    "\n",
    "- *explainabilities*: The list of explainabilities for each input image. An explainability is an intensity matrix (a matrix with values between 0 and 1) of the same size of the image tensor, which represents the importance of each pixel in the model's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3175750-1575-4d45-9b27-29e0f0377e20",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Install the dependencies if it is not already done. For more information look at the [readme](../README.md) file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf46c9b-99a7-4a67-aa2e-98aa3bfd1de1",
   "metadata": {},
   "source": [
    "##### For development on Local Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b27e513d-181f-4153-9fb6-fdda54062850",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install a virtual environment\n",
    "# Option 1:  using conda (recommended)\n",
    "# !conda create -n venv python=3.12\n",
    "# !conda activate venv\n",
    "# !pip install torch==2.6.0\n",
    "\n",
    "# Option 2: using virtualenv\n",
    "# !pip install virtualenv\n",
    "# !virtualenv -p /usr/bin/python3.12 venv\n",
    "# !source venv_lips/bin/activate\n",
    "\n",
    "### Install the welding challenge package\n",
    "# Option 1: Get the last version from Pypi\n",
    "# !pip install 'challenge_welding'\n",
    "\n",
    "# Option 2: Get the last version from github repository\n",
    "# !git clone https://github.com/XX\n",
    "# !pip install -U ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41102f3e-02ec-4cd7-b132-1d0cd2a865dd",
   "metadata": {},
   "source": [
    "##### For Google Colab Users\n",
    "You could also use a GPU device from Runtime > Change runtime type and by selecting T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ac9858-d085-4aa0-b382-bd5bf3285300",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the welding challenge package\n",
    "# Option 1: Get the last version of LIPS framework from PyPI (Recommended)\n",
    "# !pip install 'challenge_welding'\n",
    "# !pip install torch==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caee8b1e-98ed-404e-892e-66538b541f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Get the last version from github repository\n",
    "# !git clone https://github.com/XX\n",
    "# !pip install -U .\n",
    "# !pip install torch==2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f164041-0e31-453a-9d4b-5bb68de49d10",
   "metadata": {},
   "source": [
    "Attention: You may restart the session after this installation, in order that the changes be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139feb9f-9aca-4093-b760-988d4e6076cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "#repo_url = \"git+https://github.com/confianceai/Challenge-Welding-Starter-Kit.git\"\n",
    "#requirements_url = \"https://raw.githubusercontent.com/confianceai/Challenge-Welding-Starter-Kit/refs/heads/main/requirements.txt\"\n",
    "#subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", repo_url])\n",
    "#subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", requirements_url])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e14d14d-7615-43b3-bd51-f6fec7935012",
   "metadata": {},
   "source": [
    "## Build your Ai component\n",
    "\n",
    "An AI component must be a buildable Python package . It should be a folder that contains at least the following files and folders:\n",
    "   ```\n",
    "    /\n",
    "    MANIFEST.in\n",
    "    setup.py\n",
    "    requirements.txt\n",
    "    challenge_solution/\n",
    "        AIcomponent.py\n",
    "        __init__.py\n",
    " ```\n",
    "\n",
    "You can refer to the [Requirements and evaluation process](../docs/Requirements_and_Evaluation_process.md) sections for more details.\n",
    "\n",
    "Only these files will be used by the evaluation pipeline to test your AI component. The names of files and folders must not be changed.\n",
    "The most important file is the AIcomponent.py file, which serves as the interface for your AI component. This interface will be the only part used by the evaluation pipeline to interact with your component. For this reason, this file must include specific methods and classes as required by the abstract class [AIComponent interface](../challenge_welding/AIComponent_interface.py) interface.\n",
    "\n",
    "You are free to add other files as needed to make your component work.\n",
    "\n",
    "The easiest way to build your AI component for the challenge is to start with the AI component template provided in the ```AIcomponent_template``` folder of this repository and complete the folder following the process described in its ```readme.md```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d0a02-ed55-43b8-83d0-6c7f001cef70",
   "metadata": {},
   "source": [
    "## Test an AI component compatibility\n",
    "\n",
    "In this section, we will test the AI component's compatibility with the evaluation pipeline of this challenge. The following lines will verify whether the proposed AI component can be loaded properly into the evaluation pipeline and used for inference computation on a given dataset. We do not provide the computation metrics function here, but all score metrics computation functions used by the evaluation pipeline are based solely on the inference results of the AI component across multiple evaluation datasets. Therefore, if inference works with your AI component, it will ensure that the score computation and the full evaluation process will work as well.\n",
    "\n",
    "In this example, we will use the reference solution provided within this challenge, which is accessible here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7d83282-97e1-4e92-9fbc-ac3a22000cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set here the path of the AI component to test here, you can set a local filsystem path, or an url to a public git repository\n",
    "# You can replace it by the path to your own component to test\n",
    "\n",
    "AI_component_path= \"../Challenge-Welding-Reference-Solution-1\"  \n",
    "#AI_component_path=\"https://github.com/confianceai/Challenge-Welding-Reference-Solution-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef937f7-c985-4c30-bef2-f7e4dd1c143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"..\") # Uncomment this line For local tests without pkg installation, to make challenge_welding module visible \n",
    "from challenge_welding.user_interface import ChallengeUI\n",
    "from challenge_welding.inference_tools import TestAIComponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53dbf4-03c4-40d3-9a69-c89d6b565817",
   "metadata": {},
   "source": [
    "## Launch the test pipeline\n",
    "\n",
    "The test pipeline take an AI component (the solution to test) and perform the following tasks\n",
    "\n",
    "- Install your AI component as a python package \n",
    "- Load the AI component of the solution you want to test\n",
    "- Apply inference on this AI component on one or many evaluation datasets. Each inference process on a dataset generate as output a dataframe( stored as a parquet file) containing evaluation dataset metadata extended with prediction results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e327bf-490d-4425-95c9-cba6940244b7",
   "metadata": {},
   "source": [
    "## Init the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb0681b-af28-40cc-bc93-87c539ec1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize test pipeline\n",
    "myPipeline=TestAIComponent(proposed_solution_path=AI_component_path, # Set here the AI component path you want to evaluate\n",
    "                              meta_root_path=\"starter_kit_test_AI_comp_results\", # Set the directory here where pipeline results will be stored (inference results, and computed metrics)\n",
    "                              cache_strategy=\"local\", # \"local\" or \"remote\" .If set on \"local\", all image used for evaluation , will be locally stored in a cache directory. Else, image will be loaded directly from downloding\n",
    "                              cache_dir=\"test_cache\") # chosen directory for cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fddaef-6902-4025-b785-2e3ee76aa7a9",
   "metadata": {},
   "source": [
    "## Load your AI component into the evaluation environnement\n",
    "\n",
    "The load_proposed_solution() method below is divided into two main tasks:\n",
    "- Install the python package of your AI component --> ( execute the commande pip install AI_comp_path)\n",
    "- Call the load_model() method of your AIcomponent interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75924591-27d3-47b3-b6e1-7bf423321581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/Challenge-Welding-Reference-Solution-1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (2.2.3)\n",
      "Requirement already satisfied: onnxruntime==1.20.1 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (1.20.1)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (2.16.1)\n",
      "Requirement already satisfied: pillow==11.0.0 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (11.0.0)\n",
      "Requirement already satisfied: setuptools==75.8.0 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (75.8.0)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.2 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (1.15.2)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (0.7.5)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (1.26.4)\n",
      "Requirement already satisfied: keras==3.8.0 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (3.8.0)\n",
      "Requirement already satisfied: torch==2.6.0 in /opt/conda/lib/python3.12/site-packages (from challenge_solution==0.1) (2.6.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (2.2.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (3.12.1)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (0.14.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (0.3.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from keras==3.8.0->challenge_solution==0.1) (24.2)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.12/site-packages (from onnxruntime==1.20.1->challenge_solution==0.1) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.12/site-packages (from onnxruntime==1.20.1->challenge_solution==0.1) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from onnxruntime==1.20.1->challenge_solution==0.1) (4.25.6)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from onnxruntime==1.20.1->challenge_solution==0.1) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3->challenge_solution==0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3->challenge_solution==0.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.3->challenge_solution==0.1) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.1->challenge_solution==0.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.6.1->challenge_solution==0.1) (3.5.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (3.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.16.1->challenge_solution==0.1) (2.16.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (3.18.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.6.0->challenge_solution==0.1) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy->onnxruntime==1.20.1->challenge_solution==0.1) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.1->challenge_solution==0.1) (0.45.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->challenge_solution==0.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->challenge_solution==0.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->challenge_solution==0.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->challenge_solution==0.1) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->challenge_solution==0.1) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->challenge_solution==0.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->challenge_solution==0.1) (3.1.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.12/site-packages (from coloredlogs->onnxruntime==1.20.1->challenge_solution==0.1) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.6.0->challenge_solution==0.1) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras==3.8.0->challenge_solution==0.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras==3.8.0->challenge_solution==0.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.8.0->challenge_solution==0.1) (0.1.2)\n",
      "Building wheels for collected packages: challenge_solution\n",
      "  Building wheel for challenge_solution (setup.py): started\n",
      "  Building wheel for challenge_solution (setup.py): finished with status 'done'\n",
      "  Created wheel for challenge_solution: filename=challenge_solution-0.1-py3-none-any.whl size=3207725 sha256=90f291375fbb1bebe74a3f8e6c662fac9f87f5ef2675c800a0b0b0e8557c3cc8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/73/03/45/521f52708cc2e454ebec24ad27561e05c29d1383f3d3a44727\n",
      "Successfully built challenge_solution\n",
      "Installing collected packages: challenge_solution\n",
      "  Attempting uninstall: challenge_solution\n",
      "    Found existing installation: challenge_solution 0.1\n",
      "    Uninstalling challenge_solution-0.1:\n",
      "      Successfully uninstalled challenge_solution-0.1\n",
      "Successfully installed challenge_solution-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 10:19:13.169384: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-31 10:19:13.221075: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-31 10:19:14.097951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-31 10:19:15.094135: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir /home/jovyan/Challenge-Welding-Reference-Solution-1/challenge_solution\n",
      "AI component loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test-env/lib/python3.12/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "myPipeline.load_proposed_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd65bfb-9bf1-487b-a752-b82df711d9a6",
   "metadata": {},
   "source": [
    "## Load an evaluation dataset metadescription\n",
    "\n",
    "In the next cell, we load the metadata of the evaluation dataset we want to use to evaluate our AI component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a83a8a-c53d-42cf-8bda-feccbd9fba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://minio-storage.apps.confianceai-public.irtsysx.fr/challenge-welding/datasets/example_mini_dataset/metadata/ds_meta.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>class</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>welding-seams</th>\n",
       "      <th>labelling_type</th>\n",
       "      <th>resolution</th>\n",
       "      <th>path</th>\n",
       "      <th>sha256</th>\n",
       "      <th>storage_type</th>\n",
       "      <th>data_origin</th>\n",
       "      <th>blur_level</th>\n",
       "      <th>blur_class</th>\n",
       "      <th>luminosity_level</th>\n",
       "      <th>external_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_92409</td>\n",
       "      <td>OK</td>\n",
       "      <td>22/01/20 12:49</td>\n",
       "      <td>c33</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'GN\\xd7\\xa7B\\x98\\xb0r\\xa4\\xdfn\\x8cT\\x8e:\\xc07...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>701.938341</td>\n",
       "      <td>blur</td>\n",
       "      <td>50.533365</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_67943</td>\n",
       "      <td>OK</td>\n",
       "      <td>20/02/20 23:53</td>\n",
       "      <td>c102</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b's\\xf6;3i-\\x10\\xfd8y\\xf2\\xe1\\xa6JQ\\x84`\\xc6\\x...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>715.670702</td>\n",
       "      <td>blur</td>\n",
       "      <td>47.050604</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_4843</td>\n",
       "      <td>OK</td>\n",
       "      <td>20/01/20 20:34</td>\n",
       "      <td>c20</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\xdbZ\\xb3\\x12e&amp;\\xd5\\x83\\x13*\\x87S\\xe1\\x19\\xc...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>715.857380</td>\n",
       "      <td>blur</td>\n",
       "      <td>46.204245</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_25309</td>\n",
       "      <td>OK</td>\n",
       "      <td>18/07/2022 20:18</td>\n",
       "      <td>c102</td>\n",
       "      <td>operator</td>\n",
       "      <td>[960, 540]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'/c\\xe3\\xd9\\xc8|&amp;\\xaf\\xb1}\\xf6\\xe3s\\xae\\xea\\x...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>869.513006</td>\n",
       "      <td>blur</td>\n",
       "      <td>34.359280</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_76144</td>\n",
       "      <td>OK</td>\n",
       "      <td>03/10/19 21:14</td>\n",
       "      <td>c20</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\xca%\\x0c\\x92\\x1f\\x0c\\x00\\xcc\\x02\\r\\xb8\\xf1\\...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>2676.246904</td>\n",
       "      <td>clean</td>\n",
       "      <td>46.256244</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id class         timestamp welding-seams labelling_type  \\\n",
       "0  data_92409    OK    22/01/20 12:49           c33         expert   \n",
       "1  data_67943    OK    20/02/20 23:53          c102         expert   \n",
       "2   data_4843    OK    20/01/20 20:34           c20         expert   \n",
       "3  data_25309    OK  18/07/2022 20:18          c102       operator   \n",
       "4  data_76144    OK    03/10/19 21:14           c20         expert   \n",
       "\n",
       "     resolution                                               path  \\\n",
       "0  [1920, 1080]  challenge-welding/datasets/example_mini_datase...   \n",
       "1  [1920, 1080]  challenge-welding/datasets/example_mini_datase...   \n",
       "2  [1920, 1080]  challenge-welding/datasets/example_mini_datase...   \n",
       "3    [960, 540]  challenge-welding/datasets/example_mini_datase...   \n",
       "4  [1920, 1080]  challenge-welding/datasets/example_mini_datase...   \n",
       "\n",
       "                                              sha256 storage_type data_origin  \\\n",
       "0  b'GN\\xd7\\xa7B\\x98\\xb0r\\xa4\\xdfn\\x8cT\\x8e:\\xc07...           s3        real   \n",
       "1  b's\\xf6;3i-\\x10\\xfd8y\\xf2\\xe1\\xa6JQ\\x84`\\xc6\\x...           s3        real   \n",
       "2  b'\\xdbZ\\xb3\\x12e&\\xd5\\x83\\x13*\\x87S\\xe1\\x19\\xc...           s3        real   \n",
       "3  b'/c\\xe3\\xd9\\xc8|&\\xaf\\xb1}\\xf6\\xe3s\\xae\\xea\\x...           s3        real   \n",
       "4  b'\\xca%\\x0c\\x92\\x1f\\x0c\\x00\\xcc\\x02\\r\\xb8\\xf1\\...           s3        real   \n",
       "\n",
       "    blur_level blur_class  luminosity_level  \\\n",
       "0   701.938341       blur         50.533365   \n",
       "1   715.670702       blur         47.050604   \n",
       "2   715.857380       blur         46.204245   \n",
       "3   869.513006       blur         34.359280   \n",
       "4  2676.246904      clean         46.256244   \n",
       "\n",
       "                                       external_path  \n",
       "0  http://minio-storage.apps.confianceai-public.i...  \n",
       "1  http://minio-storage.apps.confianceai-public.i...  \n",
       "2  http://minio-storage.apps.confianceai-public.i...  \n",
       "3  http://minio-storage.apps.confianceai-public.i...  \n",
       "4  http://minio-storage.apps.confianceai-public.i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In this example we will choose a small dataset\n",
    "\n",
    "ds_name=\"example_mini_dataset\"\n",
    "\n",
    "# Load all metadata of your dataset as a pandas dataframe, (you can point to a local cache metafile instead of original one pointing on remote repository)\n",
    "\n",
    "my_challenge_UI=ChallengeUI()\n",
    "evaluation_ds_meta_df=my_challenge_UI.get_ds_metadata_dataframe(ds_name)\n",
    "\n",
    "display(evaluation_ds_meta_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e70108-edb7-4de7-85ab-8048a737aaa0",
   "metadata": {},
   "source": [
    "##  Perform inference on an evaluation dataset\n",
    "\n",
    "We pass the evaluation_dataframe in the method below. It use the loaded AI component to perform inference of each sample referenced in the evaluation dataframe and add the inference results as new columns\n",
    "\n",
    "The predict method of your AI component will be called with the **device** parameter on \"cuda\" . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02df7d85-68dc-4f3f-8456-91758c06f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of  batch to process for inference :  20  , start processing..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:01<00:37,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:30,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:04<00:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:06<00:25,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:08<00:23,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:09<00:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:11<00:20,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:12<00:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:14<00:16,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:15<00:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:17<00:13,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:18<00:12,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:20<00:10,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:21<00:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:23<00:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:24<00:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:26<00:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:28<00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:29<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "cumulated inference time  29.74451732635498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_df=myPipeline.perform_grouped_inference(evaluation_dataset=evaluation_ds_meta_df, # dataframe containing metadescription of your evaluation ds\n",
    "                                               results_inference_path=myPipeline.meta_root_path+\"/res_inference.parquet\", # path to file that will contains inference_results\n",
    "                                               batch_size=150 # You can group inference by batch if you want\n",
    "                                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12ffb1-1182-4e6d-b23c-578231d12199",
   "metadata": {},
   "source": [
    "You can see the inference results below. See that new column has been added :\n",
    "- \"predicted_state\" imported from \"predicitions\" key of your AI component predict method output dictionnary\n",
    "- \"scores KO\" imported from \"probabilities\" key of your AI component predict method output dictionnary\n",
    "- \"scores OK\" imported from \"probabilities\" key of your AI component predict method output dictionnary\n",
    "- \"score OOD\" imported from \"OOD scores\" key of your AI component predict method output dictionnary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c18ec49-b6ce-413e-b209-b75634a44193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>welding-seams</th>\n",
       "      <th>labelling_type</th>\n",
       "      <th>resolution</th>\n",
       "      <th>path</th>\n",
       "      <th>sha256</th>\n",
       "      <th>storage_type</th>\n",
       "      <th>data_origin</th>\n",
       "      <th>blur_level</th>\n",
       "      <th>blur_class</th>\n",
       "      <th>luminosity_level</th>\n",
       "      <th>external_path</th>\n",
       "      <th>predicted_state</th>\n",
       "      <th>scores KO</th>\n",
       "      <th>scores OK</th>\n",
       "      <th>scores UNKNOWN</th>\n",
       "      <th>scores OOD</th>\n",
       "      <th>compute_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data_92409</th>\n",
       "      <td>OK</td>\n",
       "      <td>22/01/20 12:49</td>\n",
       "      <td>c33</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'GN\\xd7\\xa7B\\x98\\xb0r\\xa4\\xdfn\\x8cT\\x8e:\\xc07...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>701.938341</td>\n",
       "      <td>blur</td>\n",
       "      <td>50.533365</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.276129</td>\n",
       "      <td>0.723871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.004692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_67943</th>\n",
       "      <td>OK</td>\n",
       "      <td>20/02/20 23:53</td>\n",
       "      <td>c102</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b's\\xf6;3i-\\x10\\xfd8y\\xf2\\xe1\\xa6JQ\\x84`\\xc6\\x...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>715.670702</td>\n",
       "      <td>blur</td>\n",
       "      <td>47.050604</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.307584</td>\n",
       "      <td>0.004692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_4843</th>\n",
       "      <td>OK</td>\n",
       "      <td>20/01/20 20:34</td>\n",
       "      <td>c20</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\xdbZ\\xb3\\x12e&amp;\\xd5\\x83\\x13*\\x87S\\xe1\\x19\\xc...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>715.857380</td>\n",
       "      <td>blur</td>\n",
       "      <td>46.204245</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.194798</td>\n",
       "      <td>0.805202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710896</td>\n",
       "      <td>0.004692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_25309</th>\n",
       "      <td>OK</td>\n",
       "      <td>18/07/2022 20:18</td>\n",
       "      <td>c102</td>\n",
       "      <td>operator</td>\n",
       "      <td>[960, 540]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'/c\\xe3\\xd9\\xc8|&amp;\\xaf\\xb1}\\xf6\\xe3s\\xae\\xea\\x...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>869.513006</td>\n",
       "      <td>blur</td>\n",
       "      <td>34.359280</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.498528</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.182223</td>\n",
       "      <td>0.004692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_76144</th>\n",
       "      <td>OK</td>\n",
       "      <td>03/10/19 21:14</td>\n",
       "      <td>c20</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\xca%\\x0c\\x92\\x1f\\x0c\\x00\\xcc\\x02\\r\\xb8\\xf1\\...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>2676.246904</td>\n",
       "      <td>clean</td>\n",
       "      <td>46.256244</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>0.977911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905888</td>\n",
       "      <td>0.004692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_41485</th>\n",
       "      <td>OK</td>\n",
       "      <td>26/07/2022 00:51</td>\n",
       "      <td>c33</td>\n",
       "      <td>operator</td>\n",
       "      <td>[960, 540]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\tK\\x04\\xf1h\\x19:\\xcd\\xe1\\xbc\\xe6\\xd2\\xb6\\x0...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>2158.350896</td>\n",
       "      <td>clean</td>\n",
       "      <td>46.735307</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.010414</td>\n",
       "      <td>0.489586</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.069381</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_79596</th>\n",
       "      <td>OK</td>\n",
       "      <td>15/07/20 08:27</td>\n",
       "      <td>c20</td>\n",
       "      <td>expert</td>\n",
       "      <td>[1920, 1080]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\xf0\\xd9\\x9f\\x16]\\xacXY\\xb5\\x06rpv/\\xbf\\xc2\\...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>2314.094661</td>\n",
       "      <td>clean</td>\n",
       "      <td>47.251992</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.202769</td>\n",
       "      <td>0.297231</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.026726</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_26044</th>\n",
       "      <td>OK</td>\n",
       "      <td>21/07/2022 14:25</td>\n",
       "      <td>c102</td>\n",
       "      <td>operator</td>\n",
       "      <td>[960, 540]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\x8c\\r\\x83\\xeb\\xf8\\x93\\xd9\\x1a\\xda\\xea\\xa8*\\...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>976.539956</td>\n",
       "      <td>clean</td>\n",
       "      <td>41.172945</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.483658</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.021310</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_22918</th>\n",
       "      <td>OK</td>\n",
       "      <td>04/07/2022 09:49</td>\n",
       "      <td>c102</td>\n",
       "      <td>operator</td>\n",
       "      <td>[960, 540]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\x87V[\\x00\\xe6\\x11L\\x02\\xca/\\x9d\\xa6\\xf9ih\\x...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>853.770358</td>\n",
       "      <td>blur</td>\n",
       "      <td>38.830967</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.989784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781015</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_24491</th>\n",
       "      <td>OK</td>\n",
       "      <td>07/07/2022 14:09</td>\n",
       "      <td>c102</td>\n",
       "      <td>operator</td>\n",
       "      <td>[960, 540]</td>\n",
       "      <td>challenge-welding/datasets/example_mini_datase...</td>\n",
       "      <td>b'\\xdcB@\\x8bj:,\\xb3\\x14\\xa7e/\\x9dYx+\\xd7\\xcd\\x...</td>\n",
       "      <td>s3</td>\n",
       "      <td>real</td>\n",
       "      <td>842.795686</td>\n",
       "      <td>blur</td>\n",
       "      <td>37.279294</td>\n",
       "      <td>http://minio-storage.apps.confianceai-public.i...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.498188</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.220375</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2857 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           class         timestamp welding-seams labelling_type    resolution  \\\n",
       "sample_id                                                                       \n",
       "data_92409    OK    22/01/20 12:49           c33         expert  [1920, 1080]   \n",
       "data_67943    OK    20/02/20 23:53          c102         expert  [1920, 1080]   \n",
       "data_4843     OK    20/01/20 20:34           c20         expert  [1920, 1080]   \n",
       "data_25309    OK  18/07/2022 20:18          c102       operator    [960, 540]   \n",
       "data_76144    OK    03/10/19 21:14           c20         expert  [1920, 1080]   \n",
       "...          ...               ...           ...            ...           ...   \n",
       "data_41485    OK  26/07/2022 00:51           c33       operator    [960, 540]   \n",
       "data_79596    OK    15/07/20 08:27           c20         expert  [1920, 1080]   \n",
       "data_26044    OK  21/07/2022 14:25          c102       operator    [960, 540]   \n",
       "data_22918    OK  04/07/2022 09:49          c102       operator    [960, 540]   \n",
       "data_24491    OK  07/07/2022 14:09          c102       operator    [960, 540]   \n",
       "\n",
       "                                                         path  \\\n",
       "sample_id                                                       \n",
       "data_92409  challenge-welding/datasets/example_mini_datase...   \n",
       "data_67943  challenge-welding/datasets/example_mini_datase...   \n",
       "data_4843   challenge-welding/datasets/example_mini_datase...   \n",
       "data_25309  challenge-welding/datasets/example_mini_datase...   \n",
       "data_76144  challenge-welding/datasets/example_mini_datase...   \n",
       "...                                                       ...   \n",
       "data_41485  challenge-welding/datasets/example_mini_datase...   \n",
       "data_79596  challenge-welding/datasets/example_mini_datase...   \n",
       "data_26044  challenge-welding/datasets/example_mini_datase...   \n",
       "data_22918  challenge-welding/datasets/example_mini_datase...   \n",
       "data_24491  challenge-welding/datasets/example_mini_datase...   \n",
       "\n",
       "                                                       sha256 storage_type  \\\n",
       "sample_id                                                                    \n",
       "data_92409  b'GN\\xd7\\xa7B\\x98\\xb0r\\xa4\\xdfn\\x8cT\\x8e:\\xc07...           s3   \n",
       "data_67943  b's\\xf6;3i-\\x10\\xfd8y\\xf2\\xe1\\xa6JQ\\x84`\\xc6\\x...           s3   \n",
       "data_4843   b'\\xdbZ\\xb3\\x12e&\\xd5\\x83\\x13*\\x87S\\xe1\\x19\\xc...           s3   \n",
       "data_25309  b'/c\\xe3\\xd9\\xc8|&\\xaf\\xb1}\\xf6\\xe3s\\xae\\xea\\x...           s3   \n",
       "data_76144  b'\\xca%\\x0c\\x92\\x1f\\x0c\\x00\\xcc\\x02\\r\\xb8\\xf1\\...           s3   \n",
       "...                                                       ...          ...   \n",
       "data_41485  b'\\tK\\x04\\xf1h\\x19:\\xcd\\xe1\\xbc\\xe6\\xd2\\xb6\\x0...           s3   \n",
       "data_79596  b'\\xf0\\xd9\\x9f\\x16]\\xacXY\\xb5\\x06rpv/\\xbf\\xc2\\...           s3   \n",
       "data_26044  b'\\x8c\\r\\x83\\xeb\\xf8\\x93\\xd9\\x1a\\xda\\xea\\xa8*\\...           s3   \n",
       "data_22918  b'\\x87V[\\x00\\xe6\\x11L\\x02\\xca/\\x9d\\xa6\\xf9ih\\x...           s3   \n",
       "data_24491  b'\\xdcB@\\x8bj:,\\xb3\\x14\\xa7e/\\x9dYx+\\xd7\\xcd\\x...           s3   \n",
       "\n",
       "           data_origin   blur_level blur_class  luminosity_level  \\\n",
       "sample_id                                                          \n",
       "data_92409        real   701.938341       blur         50.533365   \n",
       "data_67943        real   715.670702       blur         47.050604   \n",
       "data_4843         real   715.857380       blur         46.204245   \n",
       "data_25309        real   869.513006       blur         34.359280   \n",
       "data_76144        real  2676.246904      clean         46.256244   \n",
       "...                ...          ...        ...               ...   \n",
       "data_41485        real  2158.350896      clean         46.735307   \n",
       "data_79596        real  2314.094661      clean         47.251992   \n",
       "data_26044        real   976.539956      clean         41.172945   \n",
       "data_22918        real   853.770358       blur         38.830967   \n",
       "data_24491        real   842.795686       blur         37.279294   \n",
       "\n",
       "                                                external_path predicted_state  \\\n",
       "sample_id                                                                       \n",
       "data_92409  http://minio-storage.apps.confianceai-public.i...              OK   \n",
       "data_67943  http://minio-storage.apps.confianceai-public.i...         UNKNOWN   \n",
       "data_4843   http://minio-storage.apps.confianceai-public.i...              OK   \n",
       "data_25309  http://minio-storage.apps.confianceai-public.i...         UNKNOWN   \n",
       "data_76144  http://minio-storage.apps.confianceai-public.i...              OK   \n",
       "...                                                       ...             ...   \n",
       "data_41485  http://minio-storage.apps.confianceai-public.i...         UNKNOWN   \n",
       "data_79596  http://minio-storage.apps.confianceai-public.i...         UNKNOWN   \n",
       "data_26044  http://minio-storage.apps.confianceai-public.i...         UNKNOWN   \n",
       "data_22918  http://minio-storage.apps.confianceai-public.i...              OK   \n",
       "data_24491  http://minio-storage.apps.confianceai-public.i...         UNKNOWN   \n",
       "\n",
       "            scores KO  scores OK  scores UNKNOWN  scores OOD  compute_time  \n",
       "sample_id                                                                   \n",
       "data_92409   0.276129   0.723871             0.0    0.939167      0.004692  \n",
       "data_67943   0.000011   0.499989             0.5    1.307584      0.004692  \n",
       "data_4843    0.194798   0.805202             0.0    0.710896      0.004692  \n",
       "data_25309   0.001472   0.498528             0.5    1.182223      0.004692  \n",
       "data_76144   0.022089   0.977911             0.0    0.905888      0.004692  \n",
       "...               ...        ...             ...         ...           ...  \n",
       "data_41485   0.010414   0.489586             0.5    1.069381      0.012105  \n",
       "data_79596   0.202769   0.297231             0.5    1.026726      0.012105  \n",
       "data_26044   0.016342   0.483658             0.5    1.021310      0.012105  \n",
       "data_22918   0.010216   0.989784             0.0    0.781015      0.012105  \n",
       "data_24491   0.001812   0.498188             0.5    1.220375      0.012105  \n",
       "\n",
       "[2857 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78948c8f-361c-475f-ad3a-729022f181e6",
   "metadata": {},
   "source": [
    "Check the output dataframe contain columns corresponding to ouptut fields filled with correct values. \n",
    "Here the reference component tested shall create columns named, \n",
    "- predicted_states\n",
    "- scores_KO\n",
    "-  scores OK\n",
    "-   OOD_scores\n",
    "-   \n",
    "If your result dataframe is correct and the parquet is well created, then your AI comp is compatible with the evaluation pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bfe596-6ef5-4357-8d36-fe8a30392bf6",
   "metadata": {},
   "source": [
    "# Evaluation process\n",
    "\n",
    "The Trustworthy AI Challenge aim to build a trustworthy AI-Component that assists in weld seam conformity qualification. The evaluation of a trustworthy AI-Component will be done across several dimensions of trustworthy to ensure it reliability, robustness, and efficiency facing real observation that may be affected by hazards. The evaluation framework consists of six \"trust-attributes\" : \\textbf{Performance, uncertainty, robustness, ood monitoring, generalization, and drift}.  These aspects are some of the trust attributes that may determine the AI system’s ability to operate effectively in real-world scenarios as for example be robust to small environmental hazard, generalize across datasets, express confidence or be able to face anomalies.\n",
    "\n",
    "From the predictions made by the developed AI component on many evaluation datasets, we will compute a set of different evaluation criteria as discussed below:\n",
    "\n",
    "- **Performance metrics**: Measure the gain brought the AI component compared to a human only qualification process. This metrics is based on the confusion matrix and penalize strongly false negative predictions. \n",
    "\n",
    "- **Uncertainty metrics**: Measure the ability of the AI component to produce a calibrated prediction confidence indicator expressing risk of model errors.\n",
    "\n",
    "- **Robustness metrics**: Measure the ability of the AI component to have invariant output is images have slight perturbations (blut, luminosity, rotation, translation)\n",
    "\n",
    "- **OOD-Monitoring metrics**: Measure the ability of the AI component to detect if an input image is ood, and gives the appropriate output ->Unknown\n",
    "\n",
    "- **Generalisation metrics**: Measure the ability of the AI component to generalize to a unseen context.\n",
    "\n",
    "- **Drift metrics**: Measure the ability of the AI component to generalize to a unseen context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9166083a-ff58-4434-b509-de6fa7bade61",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f2bed-8c73-4e71-bf29-69e740a6bc8f",
   "metadata": {},
   "source": [
    "# Trustworthy ML Challenge Evaluation Protocol\n",
    "\n",
    "## Multi-Criteria Aggregation Methodology\n",
    "\n",
    "The evaluation of models in the trustworthy ML challenge follows a multi-criteria aggregation methodology designed to ensure a fair and reliable assessment of various attributes. The following table illustrates this metrics aggregation principle.\n",
    "\n",
    "![image](../docs/assets/Metric_tabular.png)\n",
    "\n",
    "\n",
    "The aggregation process consists of several key steps:\n",
    "\n",
    "1. Computation of Attribute Metrics\n",
    "  - Several metrics are computed for each attribute based on specific evaluation sets in order to taking into account various criteria. \n",
    "  - These evaluation sets are either constructed or generated specifically to assess different aspects of the attribute's performance.\n",
    "\n",
    "2. Normalization of Attribute Metrics :\n",
    "  - All attribute-specific metrics are transformed into a score within the range [0,1], where 1 represents the best possible performance.\n",
    "  - To achieve this normalization, appropriate transformations such as sigmoid functions or exponential decay are applied, depending on the nature of the metric.\n",
    "$$ OP_{score} = e^{-k*Metric_{OP-Perf}}\\ and\\ U_{Score} = sigmoid(Metric_{U-OP}) $$\n",
    "\n",
    "3. Attribute-KPI Aggregation\n",
    "  - A specific aggregation formula is applied at the attribute-KPI to combine these different metrics into a unified attribute score.\n",
    "  - This ensures a comprehensive representation of each attribute’s performance.\n",
    "$$KPI_{X} = agg({metric}_{X^1},..,{Xmetric}_{X^k})$$\n",
    "\n",
    "4. Piecewise Linear Rescaling of Attribute-KPI.\n",
    "  - To ensure consistency and comparability across attributes, the attribute scores undergo a piecewise linear rescaling process.\n",
    "  - This rescaling takes into account both predefined performance and confidence requirements.\n",
    "  - These adjustments ensure that the scores align with realistic evaluation constraints.\n",
    "$$f'(x) =\n",
    "\\begin{cases}\n",
    "\\frac{\\beta_1}{\\alpha_1} f(x), & 0 \\leq f(x) < \\alpha_1 \\\\\n",
    "\\frac{\\beta_2 - \\beta_1}{\\alpha_2 - \\alpha_1} (f(x) - \\alpha_1) + \\beta_1, & \\alpha_1 \\leq f(x) \\leq \\alpha_2 \\\\[8pt]\n",
    "\\frac{1 - \\beta_2}{1 - \\alpha_2} (f(x) - \\alpha_2) + \\beta_2, & \\alpha_2 < f(x) \\leq 1\n",
    "\\end{cases}$$\n",
    "\n",
    "5. Weighted Aggregation of Attributes\n",
    "  - The rescaled attribute scores are then aggregated into a final evaluation score using a weighted  mean.\n",
    "  - The weights assigned to each attribute reflect its relative importance in the overall trustworthy assessment framework.\n",
    "$$\\alpha_1*I^{perf} + \\alpha_2*I^{U} + \\alpha_3*I^{Rob} + \\alpha_4*I^{ood} + \\alpha_5*I^{gen}+\\alpha_6*I^{drift}$$\n",
    "\n",
    "The purpose of this aggregation protocol is to provide a single comprehensive score that encapsulates the six attribute scores, each derived from multiple criteria evaluated according to specific metrics.\n",
    "\n",
    "## Attribute & metrics\n",
    "\n",
    "### Performance attribute\n",
    "**Purpose**: Measures the model's predictive accuracy and efficiency, ensuring it meets baseline expectations in a controlled environment.\n",
    "\n",
    "**Evaluation sets**: Standards ML-evaluation sets based on representative draw of 20\\% of data.\n",
    "\n",
    "**Metrics**:\n",
    "  - **OP-Perf** (Operational Performance): Evaluates model performance through a operational prism using confusion-matrix based metric that consider operational criteria expressing the cost of different types of error and the criticality of different types of weld. \n",
    "       $$ex : c^{op} = \\sum_{k}^{|N|} \\sum_{i}^{true_{class}} \\sum_{j}^{pred_{class}} \\mathbb{1}_{Top_{class}(\\hat{y}_k)=j} * cost(i,j,k,k_{seam}) $$\n",
    "  - **ML-Perf** (Machine Learning Performance): Evaluates model performance through a machine learning prism using precision score based metrics.\n",
    "    $$ex : s^{ml} = \\frac{\\sum_{i=1}^{N} \\mathbb{1} (y_i = 1 \\land \\hat{y}_i = 1)}{\\sum_{i=1}^{N} \\mathbb{1} (\\hat{y}_i = 1)}$$\n",
    "  - **Inference Time (Times)**: Measures the computational efficiency and runtime performance of the model. The inference time for each image, shall be inferior to 1/12 of seconds . This constraint will be taken into account in the operational performance score computation by using penalization coefficient based on the inference time. \n",
    "\n",
    "**Performance-KPI**: Performance KPI aggregate OP-Perf and ML-Perf Metrics using weighted average penalized by time-execution to include operational time-execution requirement. \n",
    "$$ I^{Perf}=\\frac{(\\alpha_{op} e^{-k_c c^{op}} + \\alpha_{ml} s^{ml})}{1 + k_t ln(1+t)} $$\n",
    "\n",
    "### Uncertainty Quantification attribute\n",
    "**Purpose** : Evaluates the ability of the AI-Component to express a relevant and calibrated uncertainty that inform about it risk of decision errors.\n",
    "\n",
    "**Evaluation sets**: Standards ML-evaluation sets based on a representative draw of 20\\% of data\n",
    "\n",
    "**Metrics**:\n",
    "  - **U-OP** (Operational Uncertainty Gain): Assesses the theoretical operational gain of the fluzzy decision (probability) compared to the hard decision (top class).\n",
    "  $$ex : c^{U} = \\sum_{k}^{|N|} \\sum_{i}^{true_{class}} \\sum_{j}^{pred_{class}} \\hat{y}_k(j) * cost(i,j,k,k_{seam}) $$\n",
    "\n",
    "  - **U-Calib** (Calibration Quality): Evaluates how well calibrated is the expressed uncertainty (ex : a model expressing a probability of correctness of X \\% must be wrong on average (1-X)\\% of the time.)\n",
    "\n",
    "    $$ex : \\beta^U = \\sum_{m=1}^{M} \\frac{|B_m|}{N} acc(B_m) - conf(B_m)\\ (\\text{ECE})$$\n",
    "Where $B_m$ is the set of prediction that fall in the bin $[m,m+m/|M|]$ of estimated error-risk uncertainty, $Acc(B_m)$ is the accuracy (actual error-rate) on this set, and $conf(B_m)$ is the average estimated error-risk.\n",
    "\n",
    "**Uncertainty-KPI** : Uncertainty KPI that express the quality of uncertainty from U-OP Metric penalized according to the empirical calibration error rate.\n",
    "$$I^{U} = sig(k_u c^{u}) * (1 - \\beta^U) $$\n",
    "\n",
    "### Robustness attribute\n",
    "**Purpose**: Assesses model stability under perturbations such as blur, illumination changes, rotations, and translation variations.\n",
    "\n",
    "**Evaluation sets**: Generated evaluation sets using synthetic perturbation apply on a welds-balanced subset of the standards evaluation sets. \n",
    "\n",
    "**Metrics**:\n",
    "   - **Blur Robustness** : Aggregation (ex: AUC) of the ML-performance (Precision score) according to the strength-level of blur perturbation.\n",
    "   - **Luminance Robustness** : Aggregation (ex: AUC) of the ML-performance (Precision score) according to the strength-level of luminance perturbation.\n",
    "   - **Rotation Robustness** : Aggregation (ex: AUC) of the ML-performance (Precision score) according to the strength-level of rotation perturbation.\n",
    "   - **Translation Robustness**: Aggregation (ex: AUC) of the ML-performance (Precision score) according to the strength-level of translation perturbation.\n",
    "$$ex : r^x = Auc(s^ML_{/delta_1}/,..., s^ML_{/delta_k}) $$ \n",
    "\n",
    "**Robustness-KPI** : Robustness-KPI express AI-Componnent performance robustness across the 4 investigated perturbation according to an aggregation (ex: weighted average) on blur, luminance, rotation and translation robustness scores.\n",
    "$$ I^{Rob} = \\sum_{i \\in {blur,lum,rot,trans}} \\alpha_{r_i} * r^i $$ \n",
    "\n",
    "### OOD-Detection attribute\n",
    "\n",
    "**Purpose**: assess a AI-Component's ability to detect and handle data samples that deviate from its training distribution.\n",
    "\n",
    "**Evaluation sets**: a synthetic and a real ood evaluation sets containing normal and OOD data in a balanced way. For the real sample, we manually selected ood samples; for the synthetic sample, we generated synthetic ood samples by applying several transformations to selected samples (which were not ood).\n",
    "\n",
    "**Metrics**\n",
    "  - **Real-OOD score** : Quantifies the ood-detection performance using an AUROC metrics for the real evaluation set.\n",
    "  - **Syn-OOD score** : Quantifies the ood-detection performance using an AUROC metrics for the synthetic evaluation set.\n",
    "\t$$ex : s^{ood}_x = \\frac{1}{N_{\\text{ID}} N_{\\text{OOD}}} \\sum_{i=1}^{N_{\\text{OOD}}} \\sum_{j=1}^{N_{\\text{ID}}} \\mathbb{1}(\\hat{s}^{ood}_i > \\hat{s}^{ood}_j)\\ (\\text{AUROC})$$ \n",
    "\n",
    "**OOD-Monitoring KPI**: The OOD-Monitoring KPI aggregate (ex: weighted average) both real and synthetic OOD scores.\n",
    "$$I^{ood} = \\alpha_{syn}*s^{ood}_{syn} + \\alpha_{real}*s^{ood}_{real}$$\n",
    "\n",
    "### Generalization attribute\n",
    "**Purpose**: Measures how well the model maintains performance when applied to a new welds that share some characteristics with provided ones.\n",
    "\n",
    "**Evaluation sets**: we build a generalization evaluation set using data-samples of welding-seam not provided in training sets but which share with them some characteristics.\n",
    "\n",
    "**Metrics**:\n",
    "  - **OP-Perf-g** (Generalization on operational Performance): Operational performance of the AI-Component applied on a unseen welding-seam datasets.\n",
    "  - **ML-Perf-g** (Generalization ML Performance): Machine learning performance of the AI-Component applied on a unseen welding-seam datasets.\n",
    "\n",
    "**Generalization-KPI**: The generalization KPI aggregate (ex: weighted average) the operational and machine learning performance of the AI component applied on a unseen welding-seam datasets.\n",
    "$$I^{gen} = \\alpha_{op}*e^{-k_c c^{op}_g} + \\alpha_{ml}*s^{ml}_{g}$$\n",
    "\n",
    "### Drift scenario attribute\n",
    "**Purpose**: Jointly evaluate the robustness and OOD detection capabilities of the AI-Component applied to a drift-designed data sequence affected by a drift-simulating perturbation.\n",
    "\n",
    "**Evaluation sets**: we build a drift-designed data sequence by select a sequence of normal data and apply on it a increased strength perturbation along the sequence that aim to simulate a drift. We have also manually labeled as OOD on the final fraction of the sequence.\n",
    "\n",
    "**Metrics**:\n",
    "  - Perf-OP-d : \"Operational performance under drift\" of the AI-Component applied on a drift-designed data sequence.\n",
    "  - OOD-d: \"OOD-Detection score\" : Ood-detection performance using an AUROC metrics on the fraction of the drift-designed data sequence labeled as OOD.  \n",
    "\n",
    "**Drift-KPI**: Drift score aggregate (ex: average) both operational performance score (ex: exp decay of OP-Perf) and the OOD detection scores on the drift-designed data sequence.\n",
    "$$I^{Drift} = e^{-k_{op} * c^{op}_{drift}} + s^{ood}_{drift}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38026ba8-145e-46f9-9962-3a6335f7797b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test-starter-kit",
   "language": "python",
   "name": "env-test-starter-kit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
